import torch
import torch.nn as nn
import torch.nn.functional as F
import os
import numpy as np
import json
import pandas as pd
from tqdm import tqdm
import networkx as nx
from sklearn.decomposition import NMF
from scipy.sparse import csr_matrix
from torch.nn.parameter import Parameter
from layers import GraphAttentionLayer, SpGraphAttentionLayer
from utils import get_scores
from torch_geometric.nn import GATConv
from torch_geometric.nn import InnerProductDecoder
import math
import args

class geo_GAT2(torch.nn.Module):
    def __init__(self, in_channels, nhid, out_channels, heads):  # in_channels:120
        super(geo_GAT2, self).__init__()
        #ã€€1å±‚
        # self.conv1 = GATConv(in_channels, out_channels, concat=False)
        # 2å±‚
        self.conv1 = GATConv(in_channels, nhid, heads=heads)
        # è°ƒæ•´è¾“å…¥é€šé“æ•°ï¼Œå› ä¸ºå¤šå¤´æ³¨æ„åŠ›çš„è¾“å‡ºæ˜¯å¤´æ•°ä¹˜ä»¥æ¯å¤´çš„è¾“å‡ºç»´åº¦,äºŒå±‚
        self.conv2 = GATConv(nhid * heads, out_channels, concat=False)
        self.decoder = InnerProductDecoder()
        self.relu = nn.LeakyReLU(0.2)
        self.res1 = torch.nn.Linear(in_channels, nhid * heads)
        self.res2 = torch.nn.Linear(nhid * heads, nhid * heads)
        self.fc = torch.nn.Linear(nhid * heads, out_channels)

    def encode(self, x, edge_index):  # edge_index:(2,2074)
        # residual gat
        x_res = self.res1(x)  # 2å±‚
        x = self.conv1(x, edge_index) + x_res
        x_res = self.fc(x)
        x = self.relu(x)
        x = self.conv2(x, edge_index) + x_res
        x = self.relu(x)
        return x

    def decode(self, z, pos_edge_index, neg_edge_index):
        # è§£ç æ­¥éª¤ä¿æŒä¸å˜ï¼Œä½¿ç”¨å†…ç§¯æ¥è®¡ç®—è¾¹çš„å¾—åˆ†
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)
        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)


class DANMF(object):
    """
    Deep autoencoder-like non-negative matrix factorization class.
    """
    def __init__(self, graph, args, adj2):
        super(DANMF, self).__init__()
        """
        Initializing a DANMF object.
        :param graph: Networkx graph.
        :param args: Arguments object.
        """
        self.graph = graph
        self.A = nx.adjacency_matrix(self.graph)  # è¾¹æ•°2436
        self.L = nx.laplacian_matrix(self.graph)
        self.D = self.L+self.A
        self.args = args
        self.p = len(self.args.layers)
        self.A = self.A + adj2

        # å½’ä¸€åŒ–
        min_val = min(self.A.data)
        max_val = max(self.A.data)
        self.A.data = (self.A.data - min_val) / (max_val - min_val)

        t = args.threshold
        self.A.data[self.A.data < t] = 0
        self.A.data[self.A.data >= t] = 1

        self.lamb = 0.1

        self.l1_lambda = 1e-4
        self.l2_lambda = 1e-2
        self.A_ori = self.A


    def setup_z(self, i):  # é‚»æ¥çŸ©é˜µ
        """
        Setup target matrix for pre-training process.
        """
        if i == 0:
            self.Z = self.A
        else:
            self.Z = self.V_s[i-1]


    def sklearn_pretrain(self, i):
        """  NMFï¼ˆéè´ŸçŸ©é˜µåˆ†è§£ï¼‰æ¨¡å‹é¢„è®­ç»ƒæ¨¡å‹çš„å•å±‚
        Pretraining a single layer of the model with sklearn.
        :param i: Layer index.
        n_componentsï¼šæŒ‡å®šåˆ†è§£åçš„ç‰¹å¾æ•°é‡
        """
        nmf_model = NMF(n_components=self.args.layers[i],
                        init="random",
                        random_state=self.args.seed,
                        max_iter=self.args.pre_iterations)
        U = nmf_model.fit_transform(self.Z)  # (120, 120)ã€(120, 32) ç³»æ•°çŸ©é˜µ=æƒé‡çŸ©é˜µ è¡Œä¸å˜
        V = nmf_model.components_  # (120, 120)ã€(32, 120) åŸºçŸ©é˜µ åˆ—ä¸å˜
        return U, V

    def pre_training(self):
        """
        Pre-training each NMF layer.
        """
        print("\nLayer pre-training started. \n")
        # self.A = self.gc1(pre_emb, self.A)
        self.U_s = []
        self.V_s = []
        for i in tqdm(range(self.p), desc="Layers trained: ", leave=True):
            self.setup_z(i)
            U, V = self.sklearn_pretrain(i)
            self.U_s.append(U)  # å­˜å‚¨æ¯å±‚çš„ç³»æ•°çŸ©é˜µ
            self.V_s.append(V)  # å­˜å‚¨æ¯å±‚çš„åŸºçŸ©é˜µ

    def setup_Q(self):
        """
        Setting up Q matrices.
        å­˜å‚¨ä¸¤ç»„å› å­çš„ä¸­é—´ç»“æœï¼Œäº¤æ›¿æ›´æ–° U å’Œ V æ—¶ç”¨åˆ° Q çŸ©é˜µ
        é•¿åº¦ä¸º p (è¿­ä»£æ¬¡æ•°)+1
        """
        self.Q_s = [None for _ in range(self.p+1)]
        self.Q_s[self.p] = np.eye(self.args.layers[self.p-1])  # æœ€åä¸€ä¸ªå…ƒç´ åˆå§‹åŒ–ä¸ºå•ä½çŸ©é˜µï¼šQ_p=I
        for i in range(self.p-1, -1, -1):  # ä»å€’æ•°ç¬¬äºŒä¸ªå…ƒç´ å¼€å§‹ï¼Œé€æ­¥è®¡ç®—å¹¶å­˜å‚¨å…¶ä»–å±‚ Q çŸ©é˜µçš„å€¼
            self.Q_s[i] = np.dot(self.U_s[i], self.Q_s[i+1])  # å·²çŸ¥çš„ç³»æ•°çŸ©é˜µ * ä¸‹ä¸€å±‚ Q çŸ©é˜µçš„å€¼

    def update_U(self, i):
        """
        Updating left hand factors.
        :param i: Layer index.
        Î¦^T_{ğ‘–+1} -> Q_s  Î¨^ğ‘‡_{ğ‘–âˆ’1} -> ç³»æ•°çŸ©é˜µ U_s
        """
        if i == 0:
            R = self.U_s[0].dot(self.Q_s[1].dot(self.VpVpT).dot(self.Q_s[1].T))
            R = R+self.A_sq.dot(self.U_s[0].dot(self.Q_s[1].dot(self.Q_s[1].T)))
            Ru = 2*self.A.dot(self.V_s[self.p-1].T.dot(self.Q_s[1].T))  # åˆ†å­
            self.U_s[0] = (self.U_s[0]*Ru)/np.maximum(R, 10**-10)  # ä½¿ç”¨np.maximumç¡®ä¿åˆ†æ¯ä¸ä¸º0
        else:
            R = self.P.T.dot(self.P).dot(self.U_s[i]).dot(self.Q_s[i+1]).dot(self.VpVpT).dot(self.Q_s[i+1].T)
            R = R+self.A_sq.dot(self.P).T.dot(self.P).dot(self.U_s[i]).dot(self.Q_s[i+1]).dot(self.Q_s[i+1].T)
            Ru = 2*self.A.dot(self.P).T.dot(self.V_s[self.p-1].T).dot(self.Q_s[i+1].T)
            self.U_s[i] = (self.U_s[i]*Ru)/np.maximum(R, 10**-10)

    def update_P(self, i):
        """
        Setting up P matrices.
        :param i: Layer index.
        """
        if i == 0:
            self.P = self.U_s[0]
        else:
            self.P = self.P.dot(self.U_s[i])

    def update_V(self, i):
        """
        Updating right hand factors.
        :param i: Layer index.
        """
        if i < self.p-1:  # V_i
            Vu = 2*self.A.dot(self.P).T
            Vd = self.P.T.dot(self.P).dot(self.V_s[i])+self.V_s[i]
            self.V_s[i] = self.V_s[i] * Vu/np.maximum(Vd, 10**-10)
        else:  # V_p
            Vu = 2*self.A.dot(self.P).T+(self.args.lamb*self.A.dot(self.V_s[i].T)).T
            Vd = self.P.T.dot(self.P).dot(self.V_s[i])
            Vd = Vd + self.V_s[i]+(self.args.lamb*self.D.dot(self.V_s[i].T)).T
            self.V_s[i] = self.V_s[i] * Vu/np.maximum(Vd, 10**-10)

    def calculate_cost(self, i):
        """
        Calculate loss.
        :param i: Global iteration.é‡æ„æŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±
        """
        reconstruction_loss_1 = np.linalg.norm(self.A-self.P.dot(self.V_s[-1]), ord="fro")**2
        reconstruction_loss_2 = np.linalg.norm(self.V_s[-1]-self.A.dot(self.P).T, ord="fro")**2
        regularization_loss = np.trace(self.V_s[-1].dot(self.L.dot(self.V_s[-1].T)))
        self.loss.append([i+1, reconstruction_loss_1, reconstruction_loss_2, regularization_loss])


    def save_embedding(self):
        """
        Save embedding matrix.
        """
        embedding = [np.array(range(self.P.shape[0])).reshape(-1, 1), self.P, self.V_s[-1].T]
        embedding = np.concatenate(embedding, axis=1)
        columns = ["id"] + ["x_" + str(x) for x in range(self.args.layers[-1]*2)]
        return embedding

    def save_membership(self):
        """
        Save cluster membership.
        """
        index = np.argmax(self.P, axis=1)
        self.membership = {int(i): int(index[i]) for i in range(len(index))}
        with open(self.args.membership_path, "w") as f:
            json.dump(self.membership, f)

    def get_acc(self, adj_rec, adj_label):
        labels_all = adj_label.to_dense().view(-1).long()
        preds_all = (adj_rec > 0.5).view(-1).long()
        accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)
        return accuracy

    def training(self):
        """
        Training process after pre-training.
        """
        print("\n\nTraining started. \n")
        self.loss = []
        self.A_sq = self.A.dot(self.A.T)  # è®¡ç®—åæ–¹å·®çŸ©é˜µï¼Œå¢å¼ºå›¾çš„è¡¨ç¤ºï¼Œæä¾›èŠ‚ç‚¹é—´çš„ç›¸ä¼¼æ€§åº¦é‡
        for iteration in tqdm(range(self.args.iterations), desc="Training pass: ", leave=True):
            self.setup_Q()  # è®¾å®šä¸­é—´çŸ©é˜µ
            self.VpVpT = self.V_s[self.p-1].dot(self.V_s[self.p-1].T)  # è®¡ç®—åŸºçŸ©é˜µå†…ç§¯æˆ–ç›¸ä¼¼åº¦
            for i in range(self.p):  # é€å±‚å¾ªç¯
                self.update_U(i)
                self.update_P(i)
                self.update_V(i)

            if self.args.calculate_loss:
                self.calculate_cost(iteration)
                # ä¸‹è½½è¯„ä¼°ç»“æœæœ€å¥½çš„emb

        emb = self.save_embedding()
        S = self.U_s[0].dot(self.U_s[1]).dot(self.V_s[1])
        return S

